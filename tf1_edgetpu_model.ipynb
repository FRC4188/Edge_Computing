{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf1_edgetpu_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+xh4kjGIvHz47tw+wSQCo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FRC4188/Edge_Computing/blob/main/tf1_edgetpu_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "asRMlHPUG-9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Directories"
      ],
      "metadata": {
        "id": "QKRf9LI6JMvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = 'model/'\n",
        "PRETRAINED_DIR = MODEL_DIR + 'pretrained/'\n",
        "CUSTOM_DIR = MODEL_DIR + 'custom/'\n",
        "EXPORT_DIR = CUSTOM_DIR + 'export/'\n",
        "DATASET_DIR = 'dataset/'\n",
        "COMPILED_DATASET_DIR = MODEL_DIR + 'dataset/'\n",
        "\n",
        "%mkdir {MODEL_DIR} \n",
        "%mkdir {PRETRAINED_DIR}\n",
        "%mkdir {CUSTOM_DIR}\n",
        "%mkdir {EXPORT_DIR}\n",
        "%mkdir {DATASET_DIR}\n",
        "%mkdir {COMPILED_DATASET_DIR}"
      ],
      "metadata": {
        "id": "1wxei2pHJL3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Switch to Tensorflow 1.x (deprecated August 1, 2022 at time of writing). Use one or the other, not both"
      ],
      "metadata": {
        "id": "U3OLQupkHROv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "id": "d_TEJUumHK6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow-gpu==1.15.2"
      ],
      "metadata": {
        "id": "pjo3NFd4zH4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "9XnOrYsDI0No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install lvis\n",
        "\n",
        "!cd models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf1/setup.py . && pip install .\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!pip install numpy==1.19.5\n",
        "!pip uninstall -y pycocotools\n",
        "!pip install pycocotools --no-binary pycocotools"
      ],
      "metadata": {
        "id": "SVi6mTA7HbBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Setup (look for OK at end)"
      ],
      "metadata": {
        "id": "VdDfAK2nJIPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/research/object_detection/builders/model_builder_tf1_test.py"
      ],
      "metadata": {
        "id": "mKPMYxIgI7xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Dataset"
      ],
      "metadata": {
        "id": "llbbR2S1SpLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Collect pictures and/or videos of the object(s) you are trying to detect. Make sure you get it in various lightings and backgrounds so that your model can generalize the object when it is detecting it. \n",
        "\n",
        "2. Make sure the pictures are in `.jpg`, `.png`, `.bmp ` format and videos are in `.mp4`, `.mov`, `.avi` format. \n",
        "\n",
        "3. Navigate to [Roboflow](https://app.roboflow.com/) and create an account. Roboflow is an online annotator that allows us to configure our dataset for training. Follow all the steps to create an account. Then, make a new project and give it an appropriate name. Next, give the annotation group an appropriate name. For example, if I were trying to detect different brand of cars like Ford, Nissan or BMW, I would name the annotation group \"car brands\". \n",
        "\n",
        "4. Go inside your project and begin uploading the pictures and/or videos you took into the dataset by clicking the \"Upload\" tab. After it has loaded all of it in, click the green \"Finish Uploading\" button in the upper righthand corner. A pop-up will appear, prompting you to split the dataset into train, validation, and test sets. Change it if necessary. \n",
        "\n",
        "5. Begin annotating the dataset. Click onto an image and select the box tool. Draw a box around your object and only the object. Try to isolate it as much as possible, but do not worry about being perfect. Once the box has been drawn, make sure to give it an appropriate identifying class name. Once you've done so, you can reuse the class name when annotating other images of the same type. For a large dataset, annotating can be tedious. However, if you have labeled enough, you will be able to quickly train a dataset based on what you've annotated so far. It can then attempt to label your images for you and you just have to check through for any missed or incorrect labels. Also, if your object is general enough, you can use one that is built-in. \n",
        "\n",
        "6. Export your model version. Navigate out of the images by clicking the back arrow and then click \"Dataset\" on the sidebar. Generate a new version. You can add preprocessing steps in order to improve your training. Once you've chosen the desired steps, you can also choose augmentation steps. This will increase the generality of your model, i.e. how effective your model is in a variety of situations. Go to the next step and generate the model. When the version has finished generating, click on the version you just created and click \"Export\". On format, select \"TFRecords\". Also, select \"show download code\". Make sure to select \"Terminal\". Copy all the text in the box and paste it into the below form."
      ],
      "metadata": {
        "id": "dsuxMRyInmON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset from Roboflow"
      ],
      "metadata": {
        "id": "jHTyPfeYU1qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DOWNLOAD_COMMAND = \"curl -L \\\"https://app.roboflow.com/ds/Wd8kVxzsdN?key=Rj2UTtkvU9\\\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\" #@param {type:\"string\"}\n",
        "!cd dataset && {DOWNLOAD_COMMAND}"
      ],
      "metadata": {
        "id": "iD__gMPpNW8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move dataset files and rename them"
      ],
      "metadata": {
        "id": "7JGyNbItU6i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_FILE = COMPILED_DATASET_DIR + 'test.tfrecord'\n",
        "TEST_FILE = COMPILED_DATASET_DIR + 'train.tfrecord'\n",
        "LABELS_FILE = COMPILED_DATASET_DIR + 'labels.pbtxt'\n",
        "\n",
        "!cp dataset/test/*.tfrecord {TRAIN_FILE}\n",
        "!cp dataset/train/*.tfrecord {TEST_FILE}\n",
        "!cp dataset/train/*.pbtxt {LABELS_FILE}"
      ],
      "metadata": {
        "id": "1FVSSWbLS7mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Pretrained Model"
      ],
      "metadata": {
        "id": "8NoczC3nVBDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download `ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03` model from Tensorflow 1 Model Zoo"
      ],
      "metadata": {
        "id": "TZILNWTnV-S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_LINK = 'http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz' #@param {type:\"string\"}\n",
        "\n",
        "!cd {PRETRAINED_DIR} && wget {MODEL_LINK}"
      ],
      "metadata": {
        "id": "66cz6gaDVEov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract model folder from file "
      ],
      "metadata": {
        "id": "115IHdWqWYMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd {PRETRAINED_DIR} && tar -zxvf *.tar.gz"
      ],
      "metadata": {
        "id": "kRGdi7XxWX00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure pipeline file"
      ],
      "metadata": {
        "id": "seSUQZLaYBGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input number of training steps"
      ],
      "metadata": {
        "id": "bE6zuIEJi_1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TRAIN_STEPS = 1500 #@param {type:\"integer\"}\n",
        "NUM_EVAL_STEPS = int(NUM_TRAIN_STEPS / 15)"
      ],
      "metadata": {
        "id": "BzL8_91ti2tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collect Directories"
      ],
      "metadata": {
        "id": "TVnVcTCxytDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = MODEL_LINK[MODEL_LINK.index('_detection/') + 11 : MODEL_LINK.index('.tar.gz')]\n",
        "\n",
        "CHECKPOINTS_DIR = PRETRAINED_DIR + MODEL_NAME + '/model.ckpt'\n",
        "CONFIG_FILE = PRETRAINED_DIR + MODEL_NAME + '/pipeline.config' \n",
        "CUSTOM_CONFIG_FILE = CUSTOM_DIR + \"pipeline.config\""
      ],
      "metadata": {
        "id": "J1DZEr0gXLXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count number of classes from labels file"
      ],
      "metadata": {
        "id": "Xvx5cS2SywZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "  from object_detection.utils import label_map_util\n",
        "  label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "  categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=90, use_display_name=True)\n",
        "  category_index = label_map_util.create_category_index(categories)\n",
        "  return len(category_index.keys())"
      ],
      "metadata": {
        "id": "r9TqV5COYEOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure pipeline file"
      ],
      "metadata": {
        "id": "7biQkJI0yz_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(CONFIG_FILE)\n",
        "\n",
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_FILE, \"r\") as f:                                                                                                                                                                                                                     \n",
        "  proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "  text_format.Merge(proto_str, pipeline_config)  \n",
        "\n",
        "pipeline_config.model.ssd.num_classes = get_num_classes(LABELS_FILE)\n",
        "pipeline_config.train_config.batch_size = 16\n",
        "pipeline_config.train_config.num_steps = NUM_TRAIN_STEPS\n",
        "pipeline_config.train_config.fine_tune_checkpoint = CHECKPOINTS_DIR\n",
        "pipeline_config.train_input_reader.label_map_path = LABELS_FILE\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [TRAIN_FILE]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = LABELS_FILE\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [TEST_FILE]\n",
        "pipeline_config.eval_config.include_metrics_per_category = False\n",
        "pipeline_config.eval_config.num_examples = NUM_EVAL_STEPS\n",
        "\n",
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(CUSTOM_CONFIG_FILE, \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "metadata": {
        "id": "7JkU12dvYGSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View file"
      ],
      "metadata": {
        "id": "v8tnDuoBy4YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {CUSTOM_CONFIG_FILE}"
      ],
      "metadata": {
        "id": "HIC1QlXHdVLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "7u4mtS3-do-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OVERRIDE_TRAIN_STEPS = 0#@param {type:\"integer\"}\n",
        "OVERRIDE_EVAL_STEPS = OVERRIDE_TRAIN_STEPS / 15\n",
        "\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "  --pipeline_config_path={CUSTOM_CONFIG_FILE} \\\n",
        "  --model_dir={CUSTOM_DIR} \\\n",
        "  --num_train_steps={OVERRIDE_TRAIN_STEPS} \\\n",
        "  --num_eval_steps={OVERRIDE_EVAL_STEPS} \\\n",
        "  --alsologtostderr\n"
      ],
      "metadata": {
        "id": "5dbxqd4AeMON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View training and validation with Tensorboard"
      ],
      "metadata": {
        "id": "QsaeS8Ix1-Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir {CUSTOM_DIR + 'events.out.*'}"
      ],
      "metadata": {
        "id": "tLYLd9eD2CVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export for TFLite"
      ],
      "metadata": {
        "id": "qRAuf7-JnLnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "  --pipeline_config_path {pipeline_fname} \\\n",
        "  --trained_checkpoint_prefix {CUSTOM_DIR + 'model.ckpt-' + NUM_TRAIN_STEPS} \\\n",
        "  --output_directory {EXPORT_DIR} \\\n",
        "  --add_postprocessing_op"
      ],
      "metadata": {
        "id": "YrkxXL7_m8Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to TFLite"
      ],
      "metadata": {
        "id": "qZoIkPGLnkKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_NAME = 'serving_default_input:0'\n",
        "OUT0_NAME = 'StatefulPartitionedCall:3;StatefulPartitionedCall:2;StatefulPartitionedCall:1;StatefulPartitionedCall:0'\n",
        "OUT1_NAME = 'StatefulPartitionedCall:3;StatefulPartitionedCall:2;StatefulPartitionedCall:1;StatefulPartitionedCall:01'\n",
        "OUT2_NAME = 'StatefulPartitionedCall:3;StatefulPartitionedCall:2;StatefulPartitionedCall:1;StatefulPartitionedCall:02'\n",
        "OUT3_NAME = 'StatefulPartitionedCall:3;StatefulPartitionedCall:2;StatefulPartitionedCall:1;StatefulPartitionedCall:03'\n",
        "OUTPUT_NAME = OUT0_NAME + ',' + OUT1_NAME + ',' + OUT2_NAME + ',' + OUT3_NAME\n",
        "\n",
        "!tflite_convert \\\n",
        "  --output_file {EXPORT_DIR + 'tflite/converted.tflite'} \\\n",
        "  --graph_def_file {EXPORT_DIR + 'tflite/tflite_graph.pb'} \\\n",
        "  --inference_type QUANTIZED_UINT8 \\\n",
        "  --input_arrays {INPUT_NAME} \\\n",
        "  --output_arrays {OUTPUT_NAME}\\\n",
        "  --mean_values=128 \\\n",
        "  --std_dev_values=128 \\\n",
        "  --input_shapes=1,300,300,3 \\\n",
        "  --change_concat_input_ranges False \\\n",
        "  --allow_nudging_weights_to_use_fast_gemm_kernel True \\\n",
        "  --allow_custom_ops"
      ],
      "metadata": {
        "id": "HKdwUaSNnlng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to EdgeTPU"
      ],
      "metadata": {
        "id": "pOtComs5pvlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler\t"
      ],
      "metadata": {
        "id": "Ol09a4DRpxZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!edgetpu_compiler {EXPORT_DIR + 'tflite/converted.tflite'}"
      ],
      "metadata": {
        "id": "cL2aBM_6pziM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}